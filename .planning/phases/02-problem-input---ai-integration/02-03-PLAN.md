---
phase: 02-problem-input---ai-integration
plan: 03
type: execute
wave: 2
depends_on: ["02-01", "02-02"]
files_modified:
  - components/TldrawEditor.tsx
  - app/workspace/page.tsx
  - components/workspace/ChatArea.tsx
  - lib/problem-context.tsx
autonomous: false

must_haves:
  truths:
    - "Canvas captures screenshot when user pauses drawing (2-3 sec debounce)"
    - "Screenshot is sent to AI for analysis along with problem description"
    - "User sees 'AI is analyzing...' indicator when analysis starts"
    - "AI response appears in chat area with Socratic question"
    - "In-flight requests are cancelled if user continues drawing"
    - "Latest canvas state is always analyzed (no stale screenshots)"
  artifacts:
    - path: "components/TldrawEditor.tsx"
      provides: "Canvas change detection and screenshot capture"
      min_lines: 100
    - path: "components/workspace/ChatArea.tsx"
      provides: "AI conversation display and analysis indicator"
      exports: ["default"]
      min_lines: 60
    - path: "app/workspace/page.tsx"
      provides: "Workspace layout with chat area"
      min_lines: 40
  key_links:
    - from: "components/TldrawEditor.tsx"
      to: "editor.getSvgString()"
      via: "tldraw API for canvas export"
      pattern: "getSvgString"
    - from: "components/workspace/ChatArea.tsx"
      to: "/api/chat"
      via: "fetch POST with messages"
      pattern: "fetch.*api/chat"
    - from: "components/workspace/ChatArea.tsx"
      to: "lib/problem-context"
      via: "useProblem to get original problem"
      pattern: "useProblem\\(\\)"
---

<objective>
Enable automatic canvas analysis by capturing screenshots when user pauses drawing, sending to AI for Socratic question generation, and displaying responses in a chat area.

Purpose: Closes the feedback loop between student work and AI guidance. The AI can now see what the student is doing and respond with context-aware questions.

Output: Working canvas change detection with debounced screenshot capture, chat area showing AI responses, and complete problem → work → guidance cycle.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-problem-input---ai-integration/02-CONTEXT.md

# Previous plans in this phase
@.planning/phases/02-problem-input---ai-integration/02-01-SUMMARY.md
@.planning/phases/02-problem-input---ai-integration/02-02-SUMMARY.md

# Existing components to modify
@components/TldrawEditor.tsx
@app/workspace/page.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add canvas change detection and screenshot capture</name>
  <files>components/TldrawEditor.tsx, lib/problem-context.tsx</files>
  <action>
Modify TldrawEditor to detect canvas changes and capture screenshots after user pauses.

In lib/problem-context.tsx:
- Add `canvasScreenshot: string | null` to context state
- Add `setCanvasScreenshot(screenshot: string)` to update it
- This allows other components to access latest screenshot

In components/TldrawEditor.tsx:
- Import useProblem hook to access setCanvasScreenshot
- Use tldraw's `editor.store.listen()` to detect canvas changes
- Implement 2.5 second debounce: start timer on change, reset timer on new change
- When debounce completes: capture canvas as PNG using `editor.getSvgString()` then convert to data URL
- Call setCanvasScreenshot with the data URL
- Store timeout ref to enable cancellation on unmount or new changes

tldraw screenshot API:
- `editor.getSvgString()` returns SVG string of current canvas
- Convert SVG to canvas element, then to PNG data URL for smaller size
- Alternative: use `editor.getShapeAtPoint()` to check if canvas has content before capturing

Debounce implementation:
```typescript
const timeoutRef = useRef<NodeJS.Timeout | null>(null);

useEffect(() => {
  const unsubscribe = editor.store.listen(() => {
    if (timeoutRef.current) clearTimeout(timeoutRef.current);
    timeoutRef.current = setTimeout(() => {
      captureScreenshot();
    }, 2500);
  });
  return () => {
    unsubscribe();
    if (timeoutRef.current) clearTimeout(timeoutRef.current);
  };
}, [editor]);
```

DO NOT send screenshot to API here - just capture and store in context. ChatArea component will handle sending to AI.

AVOID capturing on every single change - the debounce is critical to avoid performance issues.
  </action>
  <verify>
1. Run `npm run dev`, visit workspace
2. Draw on canvas, wait 3 seconds without drawing
3. Check browser console for confirmation that screenshot was captured (add console.log in capture function)
4. Draw again, verify debounce resets (new timer starts)
  </verify>
  <done>
Canvas change detection works with 2.5 second debounce, screenshot is captured and stored in context after user pauses.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create chat area component with AI integration</name>
  <files>components/workspace/ChatArea.tsx</files>
  <action>
Create ChatArea component to display AI conversation and handle analysis requests.

Component responsibilities:
1. Monitor canvasScreenshot from problem context
2. When new screenshot arrives: send to /api/chat with problem description
3. Display "AI is analyzing..." indicator during API call
4. Display AI responses in conversation format
5. Cancel in-flight requests if new screenshot arrives (prevents stale analysis)

State to manage:
- `messages: Array<{role: 'user' | 'assistant', content: string}>` - conversation history
- `isAnalyzing: boolean` - show loading indicator
- `abortController: AbortController | null` - for cancelling requests

When screenshot updates:
1. If already analyzing: abort current request, clear controller
2. Set isAnalyzing = true
3. Create new AbortController
4. POST to /api/chat with:
   ```json
   {
     "messages": [
       { "role": "system", "content": "Original problem: {problemText or 'See image'}" },
       { "role": "user", "content": "[Canvas screenshot: base64...]" },
       ...messages (conversation history)
     ]
   }
   ```
5. Stream response and add to messages as assistant message
6. Set isAnalyzing = false

UI Layout:
- Vertical flex container with messages scrolling
- Each message: rounded background, padding, role label
- User messages: light gray background
- Assistant messages: blue tint background
- Loading indicator: animated pulse with "AI is analyzing your work..."
- Empty state: "Work on the canvas and I'll ask guiding questions"

Use Vercel AI SDK's `useChat` hook if available, or implement fetch with streaming manually.

DO NOT add text input for user to type responses yet - that's Phase 3. This phase is AI observing and asking questions only.

IMPORTANT: Always include original problem in first message so AI has context.
  </action>
  <verify>
Check components/workspace/ChatArea.tsx exports default component without TypeScript errors.
Verify it imports useProblem hook and accesses canvasScreenshot.
  </verify>
  <done>
ChatArea component exists with screenshot monitoring, AI API integration, conversation display, and request cancellation logic.
  </done>
</task>

<task type="auto">
  <name>Task 3: Wire ChatArea into workspace layout</name>
  <files>app/workspace/page.tsx</files>
  <action>
Modify workspace layout to include chat area on the right side.

Current layout: 20% problem panel (left), 80% canvas (right)
New layout: 20% problem panel (left), 60% canvas (center), 20% chat area (right)

Update flexbox structure:
```tsx
<div className="h-screen w-screen flex overflow-hidden">
  {/* Left: Problem Panel (20%) */}
  <div className="w-1/5 h-full">
    <ProblemPanel />
  </div>

  {/* Center: Canvas Panel (60%) */}
  <div className="w-3/5 h-full">
    <CanvasPanel>
      <TldrawEditor />
    </CanvasPanel>
  </div>

  {/* Right: Chat Area (20%) */}
  <div className="w-1/5 h-full">
    <ChatArea />
  </div>
</div>
```

Import ChatArea component at top of file.

Styling for ChatArea container:
- Match ProblemPanel styling (gray-50 background)
- Add border-l border-gray-200 for visual separation from canvas

DO NOT add collapsible/expandable behavior yet - that's Phase 3 (WORK-03 requirement). This phase just needs the chat area visible and functional.
  </action>
  <verify>
Run `npm run dev`, visit workspace:
1. Verify three-panel layout: problem (20%), canvas (60%), chat (20%)
2. Check that canvas is still usable in center panel
3. Verify chat area has proper background and border
  </verify>
  <done>
Workspace layout updated to three-panel design with chat area on the right displaying AI conversation.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete Phase 2 flow: problem input (text/image) → workspace display → canvas work → automatic AI analysis → Socratic questions.

Automated:
- Text and image problem input on landing page
- Problem display in workspace panel
- Canvas change detection with 2.5 second debounce
- Screenshot capture and storage
- AI analysis API integration
- Chat area with conversation display
- "Analyzing..." indicator during AI processing
- Request cancellation for stale screenshots
  </what-built>

  <how-to-verify>
**Full flow test:**

1. **Problem submission:**
   - Visit http://localhost:3000
   - Type a math problem (e.g., "Solve the quadratic equation x^2 + 5x + 6 = 0")
   - Click "Start Working"
   - Verify problem appears in left panel of workspace

2. **Image upload test:**
   - Return to landing page (click browser back)
   - Click image upload icon
   - Select an image file (any math problem image or screenshot)
   - Verify image preview appears
   - Submit and verify image displays in workspace problem panel

3. **Canvas analysis test:**
   - In workspace, draw something on canvas (write "x = ", draw a shape, anything)
   - Stop drawing and wait 3 seconds
   - Verify "AI is analyzing..." indicator appears in right chat area
   - Verify AI responds with a Socratic question (should ask about your work, not give answers)
   - Draw more, wait again, verify new AI response

4. **Conversation context test:**
   - Continue drawing and pausing
   - Verify AI's questions build on previous conversation (references earlier work)
   - Check that questions are guiding, not solving

5. **Cancellation test:**
   - Draw something, wait 2 seconds (before debounce completes)
   - Draw again immediately
   - Verify only one analysis happens (for final state, not mid-drawing state)

**Expected behavior:**
- Problem (text or image) displays correctly in left panel
- Canvas work triggers AI analysis after pause
- AI asks Socratic questions referencing the original problem and current work
- No errors in browser console
- Smooth user experience with appropriate loading states

**Success criteria:**
- All 6 Phase 2 requirements met (INIT-02, INIT-03, CANV-02, AI-01, AI-02, AI-03, AI-04)
- AI never provides direct answers, only questions
- Conversation maintains context across multiple interactions
- No TypeScript or runtime errors
  </how-to-verify>

  <resume-signal>
Type "approved" if all tests pass and AI is responding with Socratic questions.

If issues found, describe what's not working (e.g., "AI gives answers instead of questions", "screenshot not capturing", "chat area not showing responses").
  </resume-signal>
</task>

</tasks>

<verification>
**Complete Phase 2 requirements:**
- INIT-02: User can describe math problem via text ✓
- INIT-03: User can upload image of math problem ✓
- WORK-01: Original problem displays in problem reference panel ✓
- CANV-02: Canvas captures screenshot when user pauses ✓
- AI-01: AI receives canvas screenshot on user pause ✓
- AI-02: AI analyzes current work against original problem ✓
- AI-03: AI generates Socratic questions (not answers) ✓
- AI-04: AI maintains conversation context across interactions ✓

**Phase 2 goal achieved:** AI receives and analyzes user's math problem and canvas work using Socratic method.
</verification>

<success_criteria>
- Canvas change detection works reliably with 2.5 second debounce
- Screenshot capture produces valid image data
- AI API receives screenshot + problem + conversation history
- Socratic questions appear in chat area referencing student's work
- Conversation context persists across multiple canvas updates
- Request cancellation prevents analyzing stale screenshots
- Clean UI with appropriate loading states
- All Phase 2 success criteria from roadmap met
</success_criteria>

<output>
After completion, create `.planning/phases/02-problem-input---ai-integration/02-03-SUMMARY.md`
</output>
