---
phase: 02-problem-input---ai-integration
plan: 03
type: execute
wave: 2
depends_on: ["02-02"]
files_modified:
  - components/workspace/CanvasPanel.tsx
  - components/TldrawEditor.tsx
  - components/workspace/ChatPanel.tsx
  - app/api/chat/route.ts
autonomous: true

must_haves:
  truths:
    - "Canvas automatically captures screenshot when user pauses drawing"
    - "Screenshot capture is debounced (3-5 seconds after last change)"
    - "AI receives canvas screenshot along with problem and chat history"
    - "AI analyzes canvas work proactively with Socratic observations/questions"
    - "User sees 'Analyzing canvas...' during screenshot processing"
    - "Debounce timer cancels and restarts if user resumes drawing"
  artifacts:
    - path: "components/workspace/CanvasPanel.tsx"
      provides: "Screenshot capture hook and debounce logic with cancel-on-resume"
      min_lines: 80
      contains: "exportAs.*png"
    - path: "components/TldrawEditor.tsx"
      provides: "tldraw editor instance access via ref"
      min_lines: 40
      contains: "useEditor"
    - path: "app/api/chat/route.ts"
      provides: "Vision-enabled AI analysis with proactive Socratic commentary"
      contains: "image"
  key_links:
    - from: "components/workspace/CanvasPanel.tsx"
      to: "components/TldrawEditor.tsx"
      via: "useRef to access editor.exportAs('png')"
      pattern: "exportAs"
    - from: "components/workspace/CanvasPanel.tsx"
      to: "components/workspace/ChatPanel.tsx"
      via: "context to trigger AI analysis"
      pattern: "canvasDataUrl|setCanvasDataUrl"
    - from: "app/api/chat/route.ts"
      to: "AI vision model"
      via: "messages array with image content"
      pattern: "type.*image"
---

<objective>
Implement automatic canvas screenshot capture with AI vision analysis integration.

Purpose: Enable AI to "see" student's canvas work by capturing screenshots when they pause, sending images to AI for analysis, and receiving proactive Socratic questions about their work. Completes Phase 2's core value: AI analyzes canvas work against original problem with initiative-taking guidance.

Output: Working canvas-to-AI pipeline where pausing drawing triggers screenshot capture, AI analysis with proactive commentary, and contextual Socratic questions.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-problem-input---ai-integration/02-CONTEXT.md
@.planning/phases/02-problem-input---ai-integration/02-03-CONTEXT.md
@.planning/phases/02-problem-input---ai-integration/02-02-SUMMARY.md

# Existing files
@components/workspace/CanvasPanel.tsx
@components/TldrawEditor.tsx
@app/api/chat/route.ts
</context>

<tasks>

<task type="auto">
  <name>Add screenshot capture capability to canvas</name>
  <files>components/TldrawEditor.tsx, components/workspace/CanvasPanel.tsx</files>
  <action>
**TldrawEditor.tsx changes:**
- Add useEditor hook from tldraw to access editor instance
- Expose editor ref via forwardRef or return editor from component
- OR: Create captureScreenshot() function that calls editor.exportAs('png', [shapeIds])
- Export screenshot capture capability

**CanvasPanel.tsx changes:**
- Import TldrawEditor with ref access
- Create state: canvasDataUrl (stores latest screenshot as base64 data URL)
- Add onChange handler that detects canvas changes
- Implement debounce logic: 3-5 second delay after last change (per 02-03-CONTEXT.md decision)
- **Cancel-on-resume:** If user resumes drawing before debounce fires, cancel timer and restart (prevents analyzing stale screenshots)
- On debounce trigger: call editor.exportAs('png') or equivalent
- Convert exported blob to base64 data URL: `URL.createObjectURL(blob)` or `FileReader.readAsDataURL(blob)`
- Store in canvasDataUrl state
- Trigger AI analysis callback (pass to ChatPanel via context or prop)

**Debounce implementation with cancel-on-resume:**
Use setTimeout/clearTimeout pattern:
```typescript
const [debounceTimer, setDebounceTimer] = useState<NodeJS.Timeout | null>(null);

const handleCanvasChange = () => {
  // Cancel previous timer if user resumes drawing
  if (debounceTimer) clearTimeout(debounceTimer);

  const timer = setTimeout(async () => {
    // Capture screenshot
    const blob = await editor.exportAs('png');
    const dataUrl = await blobToDataUrl(blob);
    setCanvasDataUrl(dataUrl);
    onCanvasCapture?.(dataUrl); // Notify ChatPanel
  }, 4000); // 4 seconds (middle of 3-5s range)

  setDebounceTimer(timer);
};
```

**Canvas change detection:**
- tldraw provides `onChangePresence` or similar change events
- Alternative: useEffect watching editor.getCurrentPageShapeIds()
- Trigger on any shape add/update/delete

**Important:** Only capture full canvas, not just changed shapes. AI needs full context.
  </action>
  <verify>
    Draw on canvas → wait 4 seconds → console.log confirms screenshot captured
    Screenshot is valid base64 data URL
    Rapid drawing only captures once after pause (debounce works)
    Resume drawing mid-debounce → timer cancels and restarts (cancel-on-resume works)
    TypeScript compilation passes
  </verify>
  <done>Canvas captures screenshots automatically on 3-5s pause, stores as data URL, cancels/restarts on resume, triggers callback</done>
</task>

<task type="auto">
  <name>Integrate canvas screenshots with AI chat API</name>
  <files>app/api/chat/route.ts</files>
  <action>
Update /api/chat route to accept and process canvas screenshots with proactive Socratic commentary:

**Request body changes:**
- Add optional canvasImage field: `canvasImage?: string` (base64 data URL)

**AI SDK vision integration with proactive strategy:**
Use multi-modal messages with image content:

```typescript
import { streamText } from 'ai';
import { openai } from '@ai-sdk/openai'; // GPT-4 Vision

export async function POST(req: Request) {
  const { messages, problem, canvasImage } = await req.json();

  const systemMessage = `${SYSTEM_PROMPT}

**Current Problem:**
${problem.text || 'Image uploaded'}

${canvasImage ? 'You can see the student\'s current canvas work. Take initiative: analyze their progress, make observations, and ask ONE proactive Socratic question. Examples: "I notice you started by drawing X... what does that represent?" or "I see you\'re working with Y. How does this relate to the problem?" Don\'t wait for the student to ask - guide them.' : 'No canvas work yet. Ask an opening question to get them started.'}

**Proactive Commentary Strategy:**
- Take initiative with observations about their work
- Ask guiding questions, not just respond to queries
- Reference the original problem when relevant (use discretion)
- Focus on process and understanding, not answers`;

  // Build messages with vision support
  const apiMessages = messages.map((msg: any) => ({
    role: msg.role,
    content: msg.content
  }));

  // Add canvas screenshot to last user message if present
  if (canvasImage && messages.length > 0) {
    const lastUserMsgIndex = apiMessages.map((m: any) => m.role).lastIndexOf('user');
    if (lastUserMsgIndex >= 0) {
      apiMessages[lastUserMsgIndex] = {
        role: 'user',
        content: [
          { type: 'text', text: messages[lastUserMsgIndex].content },
          { type: 'image', image: canvasImage }
        ]
      };
    }
  }

  const result = streamText({
    model: openai('gpt-4-turbo'), // or gpt-4o for better vision
    messages: [
      { role: 'system', content: systemMessage },
      ...apiMessages
    ],
    temperature: 0.7,
  });

  return result.toDataStreamResponse();
}
```

**Notes:**
- GPT-4 Turbo and GPT-4o support vision (image in messages)
- Claude 3.5 Sonnet also supports vision if using Anthropic
- Data URL format works directly (base64 encoded PNG)
- Image content should be in message content array alongside text
- **Proactive commentary:** System prompt instructs AI to take initiative, not wait for questions
- **Problem context comparison:** AI uses discretion on when to reference original problem vs focus on current work

**Alternative if initial greeting:**
If messages=[] (initial greeting), attach canvas image as user message before AI responds.
  </action>
  <verify>
    POST /api/chat with canvasImage returns response referencing canvas content
    AI response includes proactive observations (e.g., "I notice you started with...")
    AI response mentions specific elements visible in screenshot
    Logs confirm image successfully sent to AI provider
  </verify>
  <done>AI chat API accepts canvas screenshots, sends to vision model with proactive Socratic commentary strategy</done>
</task>

<task type="auto">
  <name>Wire canvas capture to chat panel for analysis trigger</name>
  <files>components/workspace/ChatPanel.tsx, lib/problem-context.tsx</files>
  <action>
**Use Context-based approach:**
Extend ProblemProvider to include canvas state:
- Add canvasDataUrl state to problem-context.tsx
- Add setCanvasDataUrl() method
- CanvasPanel calls setCanvasDataUrl() when screenshot captured
- ChatPanel reads canvasDataUrl via useProblem()
- ChatPanel automatically sends analysis request when canvasDataUrl changes AND user hasn't typed recently

This approach is mandated because problem-context.tsx already exists and context is the established pattern for sharing workspace state.

**Implement auto-analysis flow (automatic only - no manual trigger button):**
1. Canvas captures screenshot → updates canvasDataUrl state
2. ChatPanel detects canvasDataUrl change (useEffect)
3. Check: user hasn't sent message in last 5 seconds (avoid interrupting active typing)
4. If clear: automatically send analysis request to /api/chat
5. Analysis request: current messages + problem + canvasImage
6. Show "Analyzing canvas..." in chat (subtle visual feedback per 02-03-CONTEXT.md)
7. AI response streams in with proactive commentary

**Cancel in-flight analysis (interruption handling):**
- If user starts typing while analysis in progress: abort fetch request
- If canvas changes during analysis: cancel old request, queue new analysis after debounce
- This ensures analysis stays focused on latest work, avoids stale screenshots

**State management:**
- isAnalyzing: boolean (show "Analyzing canvas..." indicator)
- lastAnalysisTime: timestamp (prevent duplicate analysis)

Use AbortController for request cancellation:
```typescript
const abortControllerRef = useRef<AbortController | null>(null);

const analyzeCanvas = async () => {
  // Cancel previous request (interruption handling)
  if (abortControllerRef.current) {
    abortControllerRef.current.abort();
  }

  abortControllerRef.current = new AbortController();

  fetch('/api/chat', {
    method: 'POST',
    body: JSON.stringify({ messages, problem, canvasImage }),
    signal: abortControllerRef.current.signal
  });
};
```

**No manual trigger button:** Per 02-03-CONTEXT.md, automatic analysis only. Simpler UX, less cognitive load.
  </action>
  <verify>
    Draw on canvas → pause 4 seconds → chat shows "Analyzing canvas..."
    AI response references canvas content with proactive observations (e.g., "I see you've written X...")
    Continue drawing → new analysis triggers after pause
    Type message while analysis in progress → analysis cancelled
    No manual trigger button present (automatic only)
    Build passes with no TypeScript errors
  </verify>
  <done>Canvas screenshots automatically trigger AI analysis with cancel-on-resume, proactive responses appear in chat with canvas awareness, no manual controls</done>
</task>

</tasks>

<verification>
**End-to-end flow:**
1. Enter workspace with problem
2. AI sends initial greeting
3. Start drawing on canvas
4. Pause for 3-5 seconds
5. Chat shows "Analyzing canvas..." (subtle feedback)
6. AI responds with proactive Socratic question about canvas content (e.g., "I notice you've started with X. What's your next step?")
7. Continue drawing OR reply via text
8. Both triggers work: drawing pause → analysis, text send → response
9. Resume drawing mid-analysis → analysis cancels, new debounce starts

**Technical checks:**
- Screenshot capture works (verify blob → data URL conversion)
- Debounce prevents excessive captures (3-5 second delay)
- Cancel-on-resume works (timer resets when user resumes drawing)
- AI receives images (check network tab: payload includes image data)
- AI responses include proactive observations and questions (not just reactive responses)
- No manual trigger button present (automatic only)
- No memory leaks (old screenshots released)
- Build passes: `npm run build`
- TypeScript passes: `npx tsc --noEmit`

**Requirements coverage:**
- CANV-02: Canvas captures screenshot when user pauses ✓
- AI-01: AI receives canvas screenshot on user pause ✓
- AI-02: AI analyzes current work against original problem ✓
- AI-04: AI maintains conversation context (canvas + chat + problem) ✓
</verification>

<success_criteria>
- [ ] Canvas automatically captures screenshot after 3-5 second pause
- [ ] Debounce timer cancels and restarts if user resumes drawing (cancel-on-resume)
- [ ] Screenshot sent to AI chat API as base64 data URL
- [ ] AI responses include proactive Socratic observations/questions about canvas content
- [ ] "Analyzing canvas..." indicator shows during processing (subtle feedback)
- [ ] Rapid drawing only triggers one analysis (debounce works)
- [ ] User can draw OR chat, both trigger AI guidance
- [ ] No manual trigger button (automatic only)
- [ ] Phase 2 complete: Full problem → canvas → AI analysis flow with proactive commentary
</success_criteria>

<output>
After completion, create `.planning/phases/02-problem-input---ai-integration/02-03-SUMMARY.md`
</output>
