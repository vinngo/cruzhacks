---
phase: 02-problem-input---ai-integration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - app/workspace/page.tsx
  - components/workspace/ChatPanel.tsx
  - app/api/chat/route.ts
  - lib/problem-context.tsx
autonomous: true

must_haves:
  truths:
    - "User sees chat sidebar in workspace with 20% width on right side"
    - "User can type messages in chat input at bottom of sidebar"
    - "User sees AI greeting message when entering workspace"
    - "User receives AI responses in chat after sending message"
    - "AI responses stream in real-time (not all-at-once)"
  artifacts:
    - path: "components/workspace/ChatPanel.tsx"
      provides: "Chat sidebar UI with message display and input"
      min_lines: 100
      exports: ["default"]
    - path: "app/api/chat/route.ts"
      provides: "POST handler for AI chat with streaming"
      exports: ["POST"]
    - path: "app/workspace/page.tsx"
      provides: "Three-panel layout (problem 20% | canvas 60% | chat 20%)"
      min_lines: 40
  key_links:
    - from: "components/workspace/ChatPanel.tsx"
      to: "/api/chat"
      via: "fetch POST with streaming response"
      pattern: "fetch.*api/chat"
    - from: "app/api/chat/route.ts"
      to: "lib/ai/prompt.ts"
      via: "imports SYSTEM_PROMPT"
      pattern: "SYSTEM_PROMPT"
    - from: "lib/problem-context.tsx"
      to: "components/workspace/ChatPanel.tsx"
      via: "useProblem hook provides problem for AI context"
      pattern: "useProblem"
---

<objective>
Implement complete AI chat system enabling Socratic tutoring conversation in workspace sidebar.

Purpose: Enable users to interact with AI tutor through text chat, receiving guiding questions (not answers) about their math problem. This establishes the conversational foundation before adding canvas screenshot integration in next plan.

Output: Working chat sidebar with AI streaming responses, initial greeting, and full conversation context awareness.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-problem-input---ai-integration/02-CONTEXT.md
@.planning/phases/02-problem-input---ai-integration/02-01-SUMMARY.md

# Existing files
@app/workspace/page.tsx
@lib/problem-context.tsx
@lib/ai/prompt.ts
</context>

<tasks>

<task type="auto">
  <name>Create chat sidebar UI component</name>
  <files>components/workspace/ChatPanel.tsx</files>
  <action>
Create ChatPanel.tsx as client component with:

**Layout:**
- Full height container with flex column
- Message list area (flex-grow, scroll-y-auto)
- Input area at bottom (fixed position)

**Message display:**
- Message array state: {role: 'user' | 'assistant', content: string}[]
- User messages: right-aligned, distinct styling (bg-blue-100 or similar)
- AI messages: left-aligned, distinct styling (bg-gray-100 or similar)
- Auto-scroll to bottom on new message
- Timestamp or visual separation between messages

**Input area:**
- Textarea for multi-line input (or input field for single-line)
- Send button (disabled when empty or loading)
- Enter key submits (Shift+Enter for newline if textarea)
- Clear input after send

**Loading state:**
- "AI is thinking..." indicator while waiting for response
- Disable input during loading

**Streaming support:**
- Append AI responses character-by-character as they arrive
- Use useChat hook from 'ai/react' for built-in streaming (recommended) OR manual fetch with ReadableStream

**Integration with problem context:**
- Import useProblem from lib/problem-context
- Access problemText and problemImage for sending to AI

Export default ChatPanel component.
  </action>
  <verify>
    Component renders without errors
    TypeScript compilation passes
    Manual test: Can type in input, messages display in list
  </verify>
  <done>ChatPanel.tsx exists with message display, input, and problem context integration</done>
</task>

<task type="auto">
  <name>Create AI chat API route with streaming</name>
  <files>app/api/chat/route.ts</files>
  <action>
Create POST handler at /api/chat using Vercel AI SDK:

**Request body:**
- messages: {role: 'user' | 'assistant', content: string}[]
- problem: {text?: string, imageUrl?: string} (from context)

**Implementation using AI SDK:**
```typescript
import { streamText } from 'ai';
import { openai } from '@ai-sdk/openai'; // or anthropic
import { SYSTEM_PROMPT } from '@/lib/ai/prompt';

export async function POST(req: Request) {
  const { messages, problem } = await req.json();

  // Build context-aware system message
  const systemMessage = `${SYSTEM_PROMPT}

**Current Problem:**
${problem.text || 'Image uploaded (description pending)'}

Provide ONE Socratic question to guide the student.`;

  const result = streamText({
    model: openai('gpt-4-turbo'), // or anthropic('claude-3-5-sonnet-20241022')
    messages: [
      { role: 'system', content: systemMessage },
      ...messages
    ],
    temperature: 0.7,
  });

  return result.toDataStreamResponse();
}
```

**Environment variable needed:**
- OPENAI_API_KEY (or ANTHROPIC_API_KEY if using Claude)

**Error handling:**
- Return 400 if messages missing
- Return 500 with message if AI call fails
- Log errors for debugging

Use whichever AI provider has API key available (OpenAI GPT-4 or Anthropic Claude). Both work with AI SDK.
  </action>
  <verify>
    curl -X POST http://localhost:3000/api/chat -H "Content-Type: application/json" -d '{"messages":[{"role":"user","content":"test"}],"problem":{"text":"2+2"}}' returns streaming response
    API route returns 200 with streamed text
    Environment variable check (API key present)
  </verify>
  <done>POST /api/chat exists, returns streaming AI responses using SYSTEM_PROMPT</done>
</task>

<task type="auto">
  <name>Wire chat UI to workspace and add initial greeting</name>
  <files>app/workspace/page.tsx, lib/problem-context.tsx</files>
  <action>
**Update workspace layout (app/workspace/page.tsx):**
- Change from 20/80 split to 20/60/20 split (problem | canvas | chat)
- Left: ProblemPanel (w-1/5)
- Center: CanvasPanel (w-3/5)
- Right: ChatPanel (w-1/5)
- Import and render ChatPanel as third column

**Add initial greeting capability (lib/problem-context.tsx):**
- Add chatInitialized boolean to context state
- Add initializeChat() method to context
- ChatPanel calls initializeChat() on mount if not initialized
- Initialization triggers automatic AI greeting message

**ChatPanel integration:**
- On mount: check if chatInitialized, if false call initializeChat() and send empty message to trigger greeting
- Greeting request: messages=[], problem={text/imageUrl from context}
- AI responds with opening question like "What information does this problem give you?" or "Where would you like to start?"

**Flow:**
1. User submits problem on landing → navigates to workspace
2. ChatPanel mounts → sees chatInitialized=false
3. ChatPanel calls initializeChat() → sends POST /api/chat with empty messages
4. AI returns greeting question based on problem context
5. chatInitialized set to true (prevents re-greeting on re-render)
  </action>
  <verify>
    npm run dev shows workspace with three-panel layout
    Chat sidebar visible on right (20% width)
    AI greeting appears automatically when entering workspace
    Can send message and receive response
    Layout proportions: 20% problem | 60% canvas | 20% chat
  </verify>
  <done>Workspace has three-panel layout, chat sidebar shows AI greeting on load, user can converse with AI</done>
</task>

</tasks>

<verification>
**End-to-end flow:**
1. Submit problem on landing page (text or image)
2. Navigate to workspace
3. See AI greeting in chat sidebar immediately
4. Type message in chat input
5. Send message → AI response streams in
6. Response appears in message list
7. Can continue conversation

**Technical checks:**
- TypeScript compilation: `npx tsc --noEmit`
- Build passes: `npm run build`
- No console errors in browser
- Streaming works (response appears gradually, not all at once)
- Problem context accessible to AI (greeting references problem)

**Requirements coverage:**
- AI-03: AI generates Socratic questions (not answers) ✓
- AI-04: AI maintains conversation context ✓
- AI-05: AI responds in chat sidebar ✓
</verification>

<success_criteria>
- [ ] Three-panel workspace layout (20/60/20)
- [ ] Chat sidebar visible with message list and input
- [ ] AI greeting appears automatically on workspace entry
- [ ] User can send text messages via chat input
- [ ] AI responses stream in real-time
- [ ] Conversation history maintained in message list
- [ ] AI references problem in responses (context awareness)
- [ ] Build completes without errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-problem-input---ai-integration/02-02-SUMMARY.md`
</output>
