---
phase: 02-problem-input---ai-integration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - app/api/chat/route.ts
  - lib/ai/prompts.ts
  - .env.local
autonomous: true

must_haves:
  truths:
    - "AI SDK is installed and importable"
    - "Chat API endpoint accepts messages and returns AI responses"
    - "AI uses Socratic method (asks questions, never gives answers)"
    - "API returns streaming text responses"
    - "Conversation history is maintained across requests"
  artifacts:
    - path: "app/api/chat/route.ts"
      provides: "POST endpoint for AI chat"
      exports: ["POST"]
      min_lines: 40
    - path: "lib/ai/prompts.ts"
      provides: "Socratic system prompt and instructions"
      exports: ["SOCRATIC_SYSTEM_PROMPT"]
    - path: ".env.local"
      provides: "API key configuration"
      contains: "OPENAI_API_KEY"
  key_links:
    - from: "app/api/chat/route.ts"
      to: "ai/prompts.ts"
      via: "imports system prompt"
      pattern: "import.*SOCRATIC_SYSTEM_PROMPT"
    - from: "app/api/chat/route.ts"
      to: "process.env.OPENAI_API_KEY"
      via: "reads API key from environment"
      pattern: "process\\.env\\.OPENAI_API_KEY"

user_setup:
  - service: openai
    why: "AI-powered Socratic tutoring"
    env_vars:
      - name: OPENAI_API_KEY
        source: "OpenAI Platform -> API keys (https://platform.openai.com/api-keys)"
    account_required: true
    dashboard_config: []
---

<objective>
Set up Vercel AI SDK with OpenAI for Socratic tutoring conversations, providing a chat API endpoint that asks guiding questions instead of giving answers.

Purpose: Establishes the AI foundation for analyzing student work and generating Socratic questions. This enables the core pedagogical approach of the application.

Output: Working chat API with streaming responses, Socratic system prompt, and proper conversation context handling.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-problem-input---ai-integration/02-CONTEXT.md

# Requirements context
@.planning/REQUIREMENTS.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Vercel AI SDK and OpenAI provider</name>
  <files>package.json</files>
  <action>
Install the Vercel AI SDK and OpenAI provider:

```bash
npm install ai openai
```

The `ai` package provides the core Vercel AI SDK functionality (streaming, hooks).
The `openai` package is the provider for OpenAI's API.

DO NOT install `@ai-sdk/openai` separately - the OpenAI provider is included in the core packages.

After install, verify package.json includes both dependencies.
  </action>
  <verify>
Run `npm list ai openai` to confirm both packages are installed.
Check package.json contains `"ai"` and `"openai"` in dependencies.
  </verify>
  <done>
Vercel AI SDK and OpenAI provider are installed and listed in package.json.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Socratic system prompt</name>
  <files>lib/ai/prompts.ts</files>
  <action>
Create system prompt that enforces Socratic teaching method.

Export `SOCRATIC_SYSTEM_PROMPT` as a string constant with these instructions:

**Role:** You are a Socratic math tutor. Your goal is to guide students to discover solutions themselves through thoughtful questions.

**Rules:**
1. NEVER provide direct answers or complete solutions
2. Ask ONE guiding question at a time
3. Questions should help students notice what they've done, what's missing, or what to try next
4. If student is stuck, ask about fundamentals or break problem into smaller steps
5. If student makes an error, ask questions that lead them to notice it themselves
6. Encourage thinking: "What do you notice about...", "What happens if...", "Why might..."
7. Keep responses concise and conversational (1-3 sentences)
8. Celebrate progress: acknowledge good reasoning when you see it

**Context you'll receive:**
- Original problem (text or image description)
- Canvas screenshot (student's current work)
- Conversation history

**Your responses should:**
- Reference specific parts of their work when relevant
- Build on previous questions in the conversation
- Adjust difficulty based on student's progress
- Use natural, encouraging language

Remember: Guide, don't solve. The student learns by thinking, not by being told.
  </action>
  <verify>
Check that lib/ai/prompts.ts exports SOCRATIC_SYSTEM_PROMPT as a string constant without syntax errors.
  </verify>
  <done>
Socratic system prompt exists with clear Socratic teaching rules and context expectations.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create chat API route with streaming</name>
  <files>app/api/chat/route.ts, .env.local</files>
  <action>
Create POST endpoint at app/api/chat/route.ts using Vercel AI SDK.

Import:
- `{ openai } from '@ai-sdk/openai'` (or use OpenAI constructor from 'openai' package depending on SDK version)
- `{ streamText } from 'ai'`
- `SOCRATIC_SYSTEM_PROMPT` from lib/ai/prompts

Endpoint should:
1. Accept POST request with JSON body: `{ messages: Array<{role: string, content: string}> }`
2. Extract messages from request body
3. Call streamText with:
   - model: `openai('gpt-4-turbo')` (good balance of quality and cost)
   - system: SOCRATIC_SYSTEM_PROMPT
   - messages: from request body
4. Return streaming response using `.toDataStreamResponse()`

Error handling:
- If OPENAI_API_KEY missing: return 500 with error message
- If request parsing fails: return 400 with error message
- Let AI SDK handle API errors (it provides good defaults)

Also create .env.local file with:
```
OPENAI_API_KEY=sk-...
```
(placeholder - user will add real key)

Add .env.local to .gitignore if not already present (check first).

Reference: Vercel AI SDK docs use this pattern for streaming chat endpoints. Use the latest v4 API (streamText, not deprecated methods).

DO NOT use the older `OpenAIStream` or `StreamingTextResponse` - these are deprecated in favor of `streamText` and `.toDataStreamResponse()`.
  </action>
  <verify>
1. Check app/api/chat/route.ts has no TypeScript errors
2. Check .env.local exists with OPENAI_API_KEY placeholder
3. Run `npm run dev` and verify server starts without errors
4. Check .gitignore includes .env.local
  </verify>
  <done>
Chat API route exists with proper streaming setup, Socratic system prompt integration, and environment variable configuration.
  </done>
</task>

</tasks>

<verification>
**API structure:**
- POST /api/chat accepts messages array
- Returns streaming text response
- Uses Socratic system prompt
- Handles conversation context via messages history

**Requirements met:**
- AI-03: AI generates Socratic questions (not answers) ✓
- AI-04: AI maintains conversation context ✓

**Note:** AI-01 and AI-02 (canvas analysis) will be implemented in Plan 03 after canvas screenshot capture is working.
</verification>

<success_criteria>
- Vercel AI SDK and OpenAI provider installed successfully
- Socratic system prompt clearly defines teaching behavior
- Chat API endpoint structure is correct (even without API key yet)
- Streaming response setup follows Vercel AI SDK v4 patterns
- .env.local created for API key configuration
- No TypeScript or build errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-problem-input---ai-integration/02-02-SUMMARY.md`
</output>
