---
phase: 02-problem-input---ai-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - components/landing/ChatInput.tsx
  - components/workspace/ProblemPanel.tsx
  - app/page.tsx
  - lib/problem-context.tsx
autonomous: true

must_haves:
  truths:
    - "User can type a text problem description"
    - "User can upload an image of a problem instead of text"
    - "Uploaded image shows preview before submission"
    - "Problem (text or image) displays in workspace ProblemPanel"
    - "Problem persists throughout workspace session"
  artifacts:
    - path: "lib/problem-context.tsx"
      provides: "React context for problem state management"
      exports: ["ProblemProvider", "useProblem"]
    - path: "components/landing/ChatInput.tsx"
      provides: "Text input with image upload toggle"
      min_lines: 80
    - path: "components/workspace/ProblemPanel.tsx"
      provides: "Problem display (text or image)"
      min_lines: 40
  key_links:
    - from: "app/page.tsx"
      to: "lib/problem-context.tsx"
      via: "ProblemProvider wrapper"
      pattern: "<ProblemProvider>"
    - from: "components/landing/ChatInput.tsx"
      to: "lib/problem-context.tsx"
      via: "useProblem hook"
      pattern: "useProblem\\(\\)"
    - from: "components/workspace/ProblemPanel.tsx"
      to: "lib/problem-context.tsx"
      via: "useProblem hook to read problem"
      pattern: "useProblem\\(\\)"
---

<objective>
Enable users to submit math problems via text OR image upload from the landing page, and display the problem in the workspace reference panel.

Purpose: Establishes the problem input mechanism and state management foundation for AI analysis. Users need to define what they're working on before AI can provide guidance.

Output: Working problem submission flow with text/image toggle, React context for state persistence, and problem display in workspace panel.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-problem-input---ai-integration/02-CONTEXT.md

# Phase 1 foundation
@.planning/phases/01-foundation-canvas/01-01-SUMMARY.md
@.planning/phases/01-foundation-canvas/01-04-SUMMARY.md

# Existing components to modify
@components/landing/ChatInput.tsx
@components/workspace/ProblemPanel.tsx
@app/page.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create problem context for state management</name>
  <files>lib/problem-context.tsx</files>
  <action>
Create React context to manage problem state (text or image) across landing and workspace pages.

Context should provide:
- `problemText: string | null` - User's text description
- `problemImage: { url: string, file: File } | null` - Uploaded image data
- `setProblem(text: string)` - Store text problem
- `setProblemImage(file: File)` - Store image problem (create object URL)
- `clearProblem()` - Reset state

Use React.createContext with proper TypeScript types. Export ProblemProvider component and useProblem hook.

Store image as object URL (URL.createObjectURL) for preview and display. Keep File reference for potential upload to AI service later.

DO NOT use localStorage or persistence - this phase focuses on session state only.
  </action>
  <verify>
Run `npm run dev`, check that lib/problem-context.tsx exports ProblemProvider and useProblem without TypeScript errors.
  </verify>
  <done>
Problem context exists with proper types, exports ProblemProvider and useProblem hook.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add image upload capability to ChatInput</name>
  <files>components/landing/ChatInput.tsx</files>
  <action>
Modify ChatInput component to support EITHER text input OR image upload (not both simultaneously).

Add:
- Hidden file input (accept="image/*") with ref
- Image icon/paperclip button next to text input to trigger file selector
- When image selected: hide text input, show image preview with filename
- "Remove image" button when image is displayed
- Pass image file to parent via new `onImageSelect` callback prop

Update ChatInputProps interface:
- Add `image: File | null`
- Add `onImageSelect: (file: File | null) => void`

UI behavior:
- Default: text input visible, image button visible
- After image upload: image preview visible, text input hidden, "Remove" button visible
- Clicking "Remove": clear image, show text input again
- Submit button: enabled if text OR image exists (not both)

Styling: Keep ChatGPT aesthetic with rounded corners, clean layout. Image preview should show thumbnail (max 200px height) with filename below.

DO NOT implement actual upload to server - just handle file selection and preview via object URL.
  </action>
  <verify>
Run `npm run dev`, visit landing page, verify:
1. Can type text in input field
2. Can click image icon to select image file
3. After selecting image, text input hides and preview appears
4. Can click "Remove" to clear image and show text input again
5. Submit button enables/disables correctly based on content
  </verify>
  <done>
ChatInput supports text OR image input with toggle behavior and proper visual feedback.
  </done>
</task>

<task type="auto">
  <name>Task 3: Wire problem state to landing and workspace</name>
  <files>app/page.tsx, components/workspace/ProblemPanel.tsx, app/layout.tsx</files>
  <action>
Wire the problem context throughout the application.

In app/layout.tsx:
- Wrap children with ProblemProvider to make context available app-wide

In app/page.tsx:
- Use useProblem hook to access setProblem and setProblemImage
- Add state for image: `const [image, setImage] = useState<File | null>(null)`
- Update ChatInput props to include image and onImageSelect
- In handleSubmit: call setProblem(problem) if text exists, or setProblemImage(image) if image exists
- Navigate to workspace after storing problem

In components/workspace/ProblemPanel.tsx:
- Use useProblem hook to read problemText and problemImage
- If problemText exists: render text in readable paragraph format
- If problemImage exists: render image with proper sizing (max-w-full, rounded corners)
- If neither exists: show placeholder (current behavior)
- Add heading "Your Problem" above content

Styling for ProblemPanel:
- Text: `text-base leading-relaxed text-gray-800` for readability
- Image: `max-w-full h-auto rounded-lg shadow-sm` for clean presentation
- Keep existing gray-50 background and padding

DO NOT add edit/delete functionality - just display the problem.
  </action>
  <verify>
Run `npm run dev`:
1. Type "Solve x^2 + 5x + 6 = 0" on landing, submit, verify text appears in workspace ProblemPanel
2. Refresh landing page, upload an image, submit, verify image appears in workspace ProblemPanel
3. Check that problem persists when navigating between workspace and landing (should NOT persist - fresh state on landing)
  </verify>
  <done>
Problem (text or image) flows from landing input → context → workspace display. User sees their submitted problem in the reference panel.
  </done>
</task>

</tasks>

<verification>
**End-to-end flow:**
1. User visits landing page
2. User types text problem OR uploads image
3. User submits
4. Workspace shows problem in left panel (text rendered as paragraph OR image displayed)
5. Problem visible throughout workspace session

**Requirements met:**
- INIT-02: User can describe math problem via text ✓
- INIT-03: User can upload image of math problem ✓
- WORK-01: Problem displays in problem reference panel ✓
</verification>

<success_criteria>
- Text input and image upload work as mutually exclusive options
- Problem state persists in React context during session
- ProblemPanel displays submitted problem (text or image) correctly
- Clean ChatGPT-style UI maintained on landing page
- No TypeScript errors, app runs without console errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-problem-input---ai-integration/02-01-SUMMARY.md`
</output>
